{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_T_I3m9NXwWP"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import math \n",
        "import time \n",
        "from tqdm import tqdm\n",
        "B = 4\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Node(object): #node class\n",
        "    def __init__(self):\n",
        "        self.id = 0\n",
        "        # for internal nodes\n",
        "        self.child_nodes = []\n",
        "        # for leaf nodes\n",
        "        self.data_points = []\n",
        "        self.parent = None\n",
        "        self.MBR = {\n",
        "            'x1': -1,\n",
        "            'y1': -1,\n",
        "            'x2': -1,\n",
        "            'y2': -1,\n",
        "        }\n",
        "    def perimeter(self):\n",
        "        # only calculate the half perimeter here\n",
        "        return (self.MBR['x2'] - self.MBR['x1']) + (self.MBR['y2'] - self.MBR['y1'])\n",
        "\n",
        "    def is_overflow(self):\n",
        "        if self.is_leaf():\n",
        "            if self.data_points.__len__() > B: #Checking overflows of data points, B is the upper bound.\n",
        "                return True\n",
        "            else:\n",
        "                return False\n",
        "        else:\n",
        "            if self.child_nodes.__len__() > B: #Checking overflows of child nodes, B is the upper bound.\n",
        "                return True\n",
        "            else:\n",
        "                return False\n",
        "\n",
        "    def is_root(self):\n",
        "        if self.parent is None:\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    def is_leaf(self):\n",
        "        if self.child_nodes.__len__() == 0:\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n"
      ],
      "metadata": {
        "id": "WE-UtSckZ1zZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RTree(object): #R tree class\n",
        "    def __init__(self):\n",
        "        self.root = Node() #Create a root\n",
        "    def insert(self, u, p): # insert p(data point) to u (MBR)\n",
        "        if u.is_leaf(): \n",
        "            self.add_data_point(u, p) #add the data point and update the corresponding MBR\n",
        "            if u.is_overflow():\n",
        "                self.handle_overflow(u) #handel overflow for leaf nodes\n",
        "        else:\n",
        "            v = self.choose_subtree(u, p) #choose a subtree to insert the data point to miminize the perimeter sum\n",
        "            self.insert(v, p) #keep continue to check the next layer recursively\n",
        "            self.update_mbr(v) #update the MBR for inserting the data point\n",
        "\n",
        "    def choose_subtree(self, u, p): \n",
        "        if u.is_leaf(): #find the leaf and insert the data point\n",
        "            return u\n",
        "        else:\n",
        "            min_increase = sys.maxsize #set an initial value\n",
        "            best_child = None\n",
        "            for child in u.child_nodes: #check each child to find the best node to insert the point \n",
        "                if min_increase > self.peri_increase(child, p):\n",
        "                    min_increase = self.peri_increase(child, p)\n",
        "                    best_child = child\n",
        "            return best_child\n",
        "\n",
        "    def peri_increase(self, node, p): # calculate the increase of the perimeter after inserting the new data point\n",
        "        # new perimeter - original perimeter = increase of perimeter\n",
        "        origin_mbr = node.MBR\n",
        "        x1, x2, y1, y2 = origin_mbr['x1'], origin_mbr['x2'], origin_mbr['y1'], origin_mbr['y2']\n",
        "        increase = (max([x1, x2, p['x']]) - min([x1, x2, p['x']]) +\n",
        "                    max([y1, y2, p['y']]) - min([y1, y2, p['y']])) - node.perimeter()\n",
        "        return increase\n",
        "\n",
        "\n",
        "    def handle_overflow(self, u):\n",
        "        u1, u2 = self.split(u) #u1 u2 are the two splits returned by the function \"split\"\n",
        "        # if u is root, create a new root with s1 and s2 as its' children\n",
        "        if u.is_root():\n",
        "            new_root = Node()\n",
        "            self.add_child(new_root, u1)\n",
        "            self.add_child(new_root, u2)\n",
        "            self.root = new_root\n",
        "            self.update_mbr(new_root)\n",
        "        # if u is not root, delete u, and set s1 and s2 as u's parent's new children\n",
        "        else:\n",
        "            w = u.parent\n",
        "            # copy the information of s1 into u\n",
        "            w.child_nodes.remove(u)\n",
        "            self.add_child(w, u1) #link the two splits and update the corresponding MBR\n",
        "            self.add_child(w, u2)\n",
        "            if w.is_overflow(): #check the parent node recursively\n",
        "                self.handle_overflow(w)\n",
        "            \n",
        "    def split(self, u):\n",
        "        # split u into s1 and s2\n",
        "        best_s1 = Node()\n",
        "        best_s2 = Node()\n",
        "        best_perimeter = sys.maxsize\n",
        "        # u is a leaf node\n",
        "        if u.is_leaf():\n",
        "            m = u.data_points.__len__()\n",
        "            # create two different kinds of divides\n",
        "            divides = [sorted(u.data_points, key=lambda data_point: data_point['x']),\n",
        "                       sorted(u.data_points, key=lambda data_point: data_point['y'])] #sorting the points based on X dimension and Y dimension\n",
        "            for divide in divides:\n",
        "                for i in range(math.ceil(0.4 * B), m - math.ceil(0.4 * B) + 1): #check the combinations to find a near-optimal one\n",
        "                    s1 = Node()\n",
        "                    s1.data_points = divide[0: i]\n",
        "                    self.update_mbr(s1)\n",
        "                    s2 = Node()\n",
        "                    s2.data_points = divide[i: divide.__len__()]\n",
        "                    self.update_mbr(s2)\n",
        "                    if best_perimeter > s1.perimeter() + s2.perimeter(): \n",
        "                        best_perimeter = s1.perimeter() + s2.perimeter()\n",
        "                        best_s1 = s1\n",
        "                        best_s2 = s2\n",
        "\n",
        "        # u is a internal node\n",
        "        else:\n",
        "            # create four different kinds of divides\n",
        "            m = u.child_nodes.__len__()\n",
        "            divides = [sorted(u.child_nodes, key=lambda child_node: child_node.MBR['x1']), #sorting based on MBRs\n",
        "                       sorted(u.child_nodes, key=lambda child_node: child_node.MBR['x2']),\n",
        "                       sorted(u.child_nodes, key=lambda child_node: child_node.MBR['y1']),\n",
        "                       sorted(u.child_nodes, key=lambda child_node: child_node.MBR['y2'])]\n",
        "            for divide in divides:\n",
        "                for i in range(math.ceil(0.4 * B), m - math.ceil(0.4 * B) + 1): #check the combinations\n",
        "                    s1 = Node()\n",
        "                    s1.child_nodes = divide[0: i]\n",
        "                    self.update_mbr(s1)\n",
        "                    s2 = Node()\n",
        "                    s2.child_nodes = divide[i: divide.__len__()]\n",
        "                    self.update_mbr(s2)\n",
        "                    if best_perimeter > s1.perimeter() + s2.perimeter():\n",
        "                        best_perimeter = s1.perimeter() + s2.perimeter()\n",
        "                        best_s1 = s1\n",
        "                        best_s2 = s2\n",
        "\n",
        "        for child in best_s1.child_nodes:\n",
        "            child.parent = best_s1\n",
        "        for child in best_s2.child_nodes:\n",
        "            child.parent = best_s2\n",
        "\n",
        "        return best_s1, best_s2\n",
        "\n",
        "\n",
        "    def add_child(self, node, child):\n",
        "        node.child_nodes.append(child) #add child nodes to the current parent (node) and update the MBRs. It is used in handeling overflows\n",
        "        child.parent = node\n",
        "        if child.MBR['x1'] < node.MBR['x1']:\n",
        "            node.MBR['x1'] = child.MBR['x1']\n",
        "        if child.MBR['x2'] > node.MBR['x2']:\n",
        "            node.MBR['x2'] = child.MBR['x2']\n",
        "        if child.MBR['y1'] < node.MBR['y1']:\n",
        "            node.MBR['y1'] = child.MBR['y1']\n",
        "        if child.MBR['y2'] > node.MBR['y2']:\n",
        "            node.MBR['y2'] = child.MBR['y2']\n",
        "    # return the child whose MBR requires the minimum increase in perimeter to cover p\n",
        "\n",
        "    def add_data_point(self, node, data_point): #add data points and update the the MBRS\n",
        "        node.data_points.append(data_point)\n",
        "        if data_point['x'] < node.MBR['x1']:\n",
        "            node.MBR['x1'] = data_point['x']\n",
        "        if data_point['x'] > node.MBR['x2']:\n",
        "            node.MBR['x2'] = data_point['x']\n",
        "        if data_point['y'] < node.MBR['y1']:\n",
        "            node.MBR['y1'] = data_point['y']\n",
        "        if data_point['y'] > node.MBR['y2']:\n",
        "            node.MBR['y2'] = data_point['y']\n",
        "\n",
        "\n",
        "    def update_mbr(self, node): #update MBRs when forming a new MBR. It is used in checking the combinations and update the root\n",
        "        x_list = []\n",
        "        y_list = []\n",
        "        if node.is_leaf():\n",
        "            x_list = [point['x'] for point in node.data_points]\n",
        "            y_list = [point['y'] for point in node.data_points]\n",
        "        else:\n",
        "            x_list = [child.MBR['x1'] for child in node.child_nodes] + [child.MBR['x2'] for child in node.child_nodes]\n",
        "            y_list = [child.MBR['y1'] for child in node.child_nodes] + [child.MBR['y2'] for child in node.child_nodes]\n",
        "        new_mbr = {\n",
        "            'x1': min(x_list),\n",
        "            'x2': max(x_list),\n",
        "            'y1': min(y_list),\n",
        "            'y2': max(y_list)\n",
        "        }\n",
        "        node.MBR = new_mbr\n"
      ],
      "metadata": {
        "id": "98r4z0tFh6ZP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_dataset(file_path):\n",
        "    dataset = []\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            line = line.split(' ')\n",
        "            point = {\n",
        "                'id': int(line[0]),\n",
        "                'x': float(line[1]),\n",
        "                'y': float(line[2])\n",
        "            }\n",
        "            dataset.append(point)\n",
        "    return dataset\n",
        "\n",
        "def read_queries(file_path):\n",
        "    queries = []\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            line = line.split(' ')\n",
        "            query = {\n",
        "                'id': int(line[0]),\n",
        "                'x_start': float(line[1]),\n",
        "                'x_end': float(line[2]),\n",
        "                'y_start': float(line[3]),\n",
        "                'y_end': float(line[4])\n",
        "            }\n",
        "            queries.append(query)\n",
        "    return queries\n",
        "\n",
        "def range_query(root, query):\n",
        "    result = []\n",
        "\n",
        "    def search(node, query):\n",
        "        if node.is_leaf():\n",
        "            for data_point in node.data_points:\n",
        "                if query['x_start'] <= data_point['x'] <= query['x_end'] and query['y_start'] <= data_point['y'] <= query['y_end']:\n",
        "                    result.append(data_point)\n",
        "        else:\n",
        "            for child in node.child_nodes:\n",
        "                if overlap(child.MBR, query):\n",
        "                    search(child, query)\n",
        "\n",
        "    search(root, query)\n",
        "    return len(result)\n",
        "\n",
        "def overlap(mbr, query):\n",
        "    if query['x_end'] < mbr['x1'] or query['x_start'] > mbr['x2']:\n",
        "        return False\n",
        "    if query['y_end'] < mbr['y1'] or query['y_start'] > mbr['y2']:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "def build_rtree(dataset):\n",
        "    rtree = RTree()\n",
        "    total_points = len(dataset)\n",
        "\n",
        "    with tqdm(total=total_points, desc='Building R-tree') as pbar:\n",
        "        for i, point in enumerate(dataset):\n",
        "            rtree.insert(rtree.root, point)\n",
        "            pbar.update(1)\n",
        "            time.sleep(0.01)  # Optional: Sleep to control the progress bar speed\n",
        "\n",
        "    return rtree\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dC4n293aYyWV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sequential_scan(dataset, query_file):\n",
        "    query_results = []\n",
        "    with open(query_file, 'r') as file:\n",
        "        for line in tqdm(file, desc='Sequential Scan', total=200):\n",
        "            line = line.split(' ')\n",
        "            query_id = int(line[0])\n",
        "            x1, x2 = float(line[1]), float(line[2])\n",
        "            y1, y2 = float(line[3]), float(line[4])\n",
        "            \n",
        "            count = 0\n",
        "            for point in dataset:\n",
        "                if x1 <= point['x'] <= x2 and y1 <= point['y'] <= y2:\n",
        "                    count += 1\n",
        "            \n",
        "            query_results.append((query_id, count))\n",
        "    \n",
        "    return query_results\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UUhHCzG7mwaO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_file = '/content/sample_data/Dataset.txt'\n",
        "queries_file = '/content/sample_data/quiries.txt'\n",
        "output_file = 'output.txt'\n",
        "\n",
        "dataset = read_dataset(dataset_file)\n",
        "queries = read_queries(queries_file)\n",
        "# measure and show Rtree building time\n",
        "go_build = time.time()\n",
        "rtree = build_rtree(dataset)\n",
        "end_build = time.time() - go_build\n",
        "# Sequential scan benchmark\n",
        "start_time = time.time()\n",
        "seq_result = sequential_scan(dataset, queries_file)\n",
        "sequential_scan_time = time.time() - start_time\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n98w_d6SlIVO",
        "outputId": "e79680b2-ab8e-456f-ae41-45a583c0755b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building R-tree: 100%|██████████| 150000/150000 [26:53<00:00, 92.99it/s]\n",
            "Sequential Scan: 100%|██████████| 200/200 [00:04<00:00, 49.08it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Range queries with R-tree\n",
        "total_query_time = 0\n",
        "query_results = []\n",
        "\n",
        "for query in tqdm(queries, desc='Range Queries'):\n",
        "  start_time = time.time()\n",
        "  count = range_query(rtree.root, query)\n",
        "  query_time = time.time() - start_time\n",
        "  total_query_time += query_time\n",
        "  print(count)\n",
        "  query_results.append(count)\n",
        "avg_query_time = total_query_time / len(queries)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZXvwLbsrTTi",
        "outputId": "62390b35-0116-4f5b-8ec3-ca17fcfef194"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Range Queries: 100%|██████████| 200/200 [00:00<00:00, 2220.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n",
            "12\n",
            "10\n",
            "5\n",
            "6\n",
            "13\n",
            "13\n",
            "7\n",
            "7\n",
            "10\n",
            "3\n",
            "8\n",
            "12\n",
            "6\n",
            "6\n",
            "8\n",
            "6\n",
            "7\n",
            "8\n",
            "6\n",
            "6\n",
            "10\n",
            "6\n",
            "4\n",
            "7\n",
            "9\n",
            "13\n",
            "12\n",
            "8\n",
            "8\n",
            "10\n",
            "11\n",
            "4\n",
            "4\n",
            "4\n",
            "6\n",
            "9\n",
            "6\n",
            "4\n",
            "8\n",
            "8\n",
            "6\n",
            "4\n",
            "10\n",
            "6\n",
            "6\n",
            "8\n",
            "10\n",
            "7\n",
            "4\n",
            "9\n",
            "9\n",
            "8\n",
            "9\n",
            "10\n",
            "4\n",
            "6\n",
            "3\n",
            "4\n",
            "8\n",
            "8\n",
            "13\n",
            "3\n",
            "5\n",
            "7\n",
            "9\n",
            "8\n",
            "8\n",
            "9\n",
            "5\n",
            "8\n",
            "6\n",
            "9\n",
            "9\n",
            "3\n",
            "9\n",
            "10\n",
            "7\n",
            "8\n",
            "14\n",
            "6\n",
            "14\n",
            "3\n",
            "7\n",
            "3\n",
            "3\n",
            "5\n",
            "11\n",
            "3\n",
            "8\n",
            "10\n",
            "2\n",
            "9\n",
            "8\n",
            "5\n",
            "2\n",
            "17\n",
            "9\n",
            "2\n",
            "7\n",
            "10\n",
            "4\n",
            "8\n",
            "7\n",
            "7\n",
            "9\n",
            "12\n",
            "11\n",
            "5\n",
            "7\n",
            "11\n",
            "10\n",
            "4\n",
            "6\n",
            "4\n",
            "11\n",
            "10\n",
            "7\n",
            "10\n",
            "7\n",
            "9\n",
            "5\n",
            "11\n",
            "14\n",
            "8\n",
            "7\n",
            "10\n",
            "7\n",
            "5\n",
            "5\n",
            "5\n",
            "6\n",
            "8\n",
            "8\n",
            "10\n",
            "7\n",
            "5\n",
            "6\n",
            "10\n",
            "6\n",
            "8\n",
            "7\n",
            "7\n",
            "7\n",
            "8\n",
            "9\n",
            "4\n",
            "11\n",
            "2\n",
            "8\n",
            "11\n",
            "4\n",
            "3\n",
            "6\n",
            "10\n",
            "5\n",
            "6\n",
            "10\n",
            "5\n",
            "7\n",
            "9\n",
            "4\n",
            "8\n",
            "9\n",
            "8\n",
            "6\n",
            "7\n",
            "6\n",
            "6\n",
            "9\n",
            "6\n",
            "14\n",
            "9\n",
            "6\n",
            "9\n",
            "2\n",
            "4\n",
            "9\n",
            "6\n",
            "7\n",
            "6\n",
            "3\n",
            "6\n",
            "14\n",
            "10\n",
            "5\n",
            "8\n",
            "12\n",
            "8\n",
            "11\n",
            "5\n",
            "3\n",
            "11\n",
            "2\n",
            "11\n",
            "6\n",
            "8\n",
            "7\n",
            "8\n",
            "6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(output_file, 'w') as file:\n",
        "  file.write(f\"Sequential Scan Time: {sequential_scan_time} seconds\\n\")\n",
        "  file.write(f\"Total RTree building Time: {end_build} seconds\\n\")\n",
        "  for s,q in seq_result:\n",
        "    file.write(f\"returned counts with sequential scan: {q}\\n\")\n",
        "  total_time = 0\n",
        "  file.write(\"Query Results:\\n\")\n",
        "  for result in query_results:\n",
        "    file.write(f\"{result}\\n\")\n",
        "    total_time = total_query_time\n",
        "  avg_time = avg_query_time\n",
        "  file.write(f\"Total Query Time: {total_time} seconds\\n\")\n",
        "  file.write(f\"Average Query Time: {avg_time} seconds\\n\")\n",
        "  tim = sequential_scan_time/(math.ceil(total_time))\n",
        "  file.write(f\"R-Tree Based Search is {tim} times faster than sequential scan\")"
      ],
      "metadata": {
        "id": "s3mG-WuorYL2"
      },
      "execution_count": 23,
      "outputs": []
    }
  ]
}